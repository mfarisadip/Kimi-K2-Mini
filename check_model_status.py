import torch
import json
import os
from pathlib import Path
from safetensors import safe_open

print('ğŸ” K2-Mini æ¨¡å‹çŠ¶æ€æ£€æŸ¥')
print('='*50)

model_path = Path('k2-mini')

# 1. æ£€æŸ¥æ–‡ä»¶
print('\n1. æ¨¡å‹æ–‡ä»¶:')
for f in sorted(model_path.glob('*.safetensors')):
    size_gb = f.stat().st_size / (1024**3)
    print(f'  {f.name}: {size_gb:.1f} GB')

# 2. æ£€æŸ¥é…ç½®
print('\n2. æ¨¡å‹é…ç½®:')
with open(model_path / 'config.json') as f:
    config = json.load(f)
    print(f'  æ¶æ„: {config.get("architectures", ["Unknown"])[0]}')
    print(f'  å±‚æ•°: {config.get("num_hidden_layers")}')
    print(f'  è·¯ç”±ä¸“å®¶æ•°: {config.get("n_routed_experts")}')
    print(f'  å…±äº«ä¸“å®¶æ•°: {config.get("n_shared_experts")}')
    print(f'  éšè—ç»´åº¦: {config.get("hidden_size")}')
    print(f'  æ¯ä¸ªtokenä½¿ç”¨ä¸“å®¶æ•°: {config.get("num_experts_per_tok")}')

# 3. æ£€æŸ¥æƒé‡ç´¢å¼•
print('\n3. æƒé‡åˆ†å¸ƒ:')
with open(model_path / 'model.safetensors.index.json') as f:
    index = json.load(f)
    weight_map = index['weight_map']
    
    # ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶çš„æƒé‡æ•°
    file_counts = {}
    for weight_name, file_name in weight_map.items():
        file_counts[file_name] = file_counts.get(file_name, 0) + 1
    
    for file_name, count in sorted(file_counts.items()):
        print(f'  {file_name}: {count} ä¸ªæƒé‡')

# 4. æ£€æŸ¥å…³é”®æƒé‡
print('\n4. æ£€æŸ¥å…³é”®æƒé‡å­˜åœ¨æ€§:')
key_patterns = [
    'model.embed_tokens.weight',
    'model.layers.0.self_attn.q_proj.weight',
    'model.layers.0.mlp.gate.weight',
    'model.layers.0.mlp.experts.0.down_proj.weight',
    'model.layers.0.mlp.shared_experts.down_proj.weight',
    'lm_head.weight'
]

for pattern in key_patterns:
    exists = any(pattern in k for k in weight_map.keys())
    status = 'âœ“' if exists else 'âœ—'
    print(f'  {status} {pattern}')

# 5. æ£€æŸ¥å…±äº«ä¸“å®¶æƒé‡
print('\n5. å…±äº«ä¸“å®¶æƒé‡çŠ¶æ€:')
shared_expert_weights = [k for k in weight_map.keys() if 'shared_experts' in k]
print(f'  æ‰¾åˆ° {len(shared_expert_weights)} ä¸ªå…±äº«ä¸“å®¶æƒé‡')
if shared_expert_weights:
    print('  ç¤ºä¾‹:')
    for weight in shared_expert_weights[:3]:
        print(f'    - {weight}')

print('\næ£€æŸ¥å®Œæˆ\!')
