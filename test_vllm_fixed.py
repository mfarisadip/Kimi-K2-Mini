#\!/usr/bin/env python3

def main():
    from vllm import LLM, SamplingParams
    import torch
    import os
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    
    print("\nğŸš€ vLLM K2-Mini æµ‹è¯• (ä¿®å¤ç‰ˆ)\n")
    
    model_path = "./k2-mini"
    
    try:
        # æ£€æŸ¥GPUä¿¡æ¯
        print(f"GPUä¿¡æ¯:")
        print(f"  è®¾å¤‡: {torch.cuda.get_device_name(0)}")
        print(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        print(f"\næ­£åœ¨ä½¿ç”¨vLLMåŠ è½½K2-Miniæ¨¡å‹...")
        print(f"  æ¨¡å‹è·¯å¾„: {model_path}")
        
        # åˆ›å»ºLLMå®ä¾‹ï¼ˆæ›´ä¿å®ˆçš„è®¾ç½®ï¼‰
        llm = LLM(
            model=model_path,
            trust_remote_code=True,
            dtype="float16",
            gpu_memory_utilization=0.6,  # é™ä½å†…å­˜ä½¿ç”¨
            max_model_len=1024,          # æ›´å°çš„åºåˆ—é•¿åº¦
            tensor_parallel_size=1,
            enforce_eager=True,          # ç¦ç”¨CUDAå›¾ä¼˜åŒ–
            disable_custom_all_reduce=True,
            quantization=None,           # ç¦ç”¨é‡åŒ–
            seed=42
        )
        
        print(f"âœ… vLLMæ¨¡å‹åŠ è½½æˆåŠŸï¼")
        
        # è®¾ç½®é‡‡æ ·å‚æ•°
        sampling_params = SamplingParams(
            temperature=0.7,
            top_p=0.9,
            max_tokens=50,  # å‡å°‘ç”Ÿæˆé•¿åº¦
            stop=["\n"]
        )
        
        # ç®€å•æµ‹è¯•
        prompt = "äººå·¥æ™ºèƒ½æ˜¯"
        
        print(f"\nğŸ“ æµ‹è¯•ç”Ÿæˆ: {prompt}")
        
        # ç”Ÿæˆ
        outputs = llm.generate([prompt], sampling_params)
        
        output = outputs[0]
        generated_text = output.outputs[0].text
        
        print(f"\nç”Ÿæˆç»“æœ:")
        print(f"è¾“å…¥: {prompt}")
        print(f"è¾“å‡º: {generated_text}")
        
        print(f"\nğŸ‰ vLLMæµ‹è¯•æˆåŠŸï¼K2-Miniæ¨¡å‹è¿è¡Œæ­£å¸¸ï¼")
        
    except RuntimeError as e:
        if "CUDA out of memory" in str(e) or "NVML_SUCCESS" in str(e):
            print(f"\nâŒ GPUå†…å­˜ä¸è¶³é”™è¯¯: {e}")
            print(f"\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            print(f"1. å½“å‰MIGå®ä¾‹åªæœ‰10GBæ˜¾å­˜ï¼Œä¸è¶³ä»¥è¿è¡Œ32.5Bæ¨¡å‹")
            print(f"2. éœ€è¦å®Œæ•´çš„H100 GPU (80GB)è¿›è¡Œæ¨ç†")
            print(f"3. æˆ–è€…ä½¿ç”¨CPUæ¨ç†ï¼ˆé€Ÿåº¦ä¼šå¾ˆæ…¢ï¼‰")
        else:
            print(f"\nâŒ å…¶ä»–CUDAé”™è¯¯: {e}")
            
    except Exception as e:
        print(f"\nâŒ å…¶ä»–é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
