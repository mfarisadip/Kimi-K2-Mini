#\!/usr/bin/env python3
import torch
import json
from safetensors import safe_open
from safetensors.torch import save_file
from pathlib import Path
import shutil

print('ğŸ”§ ä¿®å¤K2-Miniæƒé‡æ–‡ä»¶...')

model_path = Path('k2-mini')
backup_path = Path('k2-mini-backup-weights')

# åˆ›å»ºå¤‡ä»½
if not backup_path.exists():
    print('åˆ›å»ºæƒé‡å¤‡ä»½...')
    shutil.copytree(model_path, backup_path)
    print('âœ… å¤‡ä»½å®Œæˆ')

# åŠ è½½ç´¢å¼•
with open(model_path / 'model.safetensors.index.json', 'r') as f:
    index = json.load(f)

# æ‰¾å‡ºéœ€è¦ä¿®å¤çš„æƒé‡
bias_keys = [k for k in index['weight_map'] if 'e_score_correction_bias' in k]
print(f'\næ‰¾åˆ° {len(bias_keys)} ä¸ªéœ€è¦ä¿®å¤çš„æƒé‡')

# æŒ‰æ–‡ä»¶åˆ†ç»„
files_to_fix = {}
for key in bias_keys:
    file_name = index['weight_map'][key]
    if file_name not in files_to_fix:
        files_to_fix[file_name] = []
    files_to_fix[file_name].append(key)

# ä¿®å¤æ¯ä¸ªæ–‡ä»¶
for file_name, keys in files_to_fix.items():
    print(f'\nä¿®å¤ {file_name}...')
    file_path = model_path / file_name
    
    # åŠ è½½æ‰€æœ‰æƒé‡
    weights = {}
    with safe_open(file_path, framework='pt') as f:
        for key in f.keys():
            tensor = f.get_tensor(key)
            if key in keys:
                # æˆªæ–­åˆ°16ç»´
                print(f'  ä¿®å¤ {key}: {tensor.shape} -> torch.Size([16])')
                weights[key] = tensor[:16]
            else:
                weights[key] = tensor
    
    # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
    save_file(weights, file_path)
    print(f'  âœ… {file_name} ä¿®å¤å®Œæˆ')

print('\nâœ… æ‰€æœ‰æƒé‡æ–‡ä»¶ä¿®å¤å®Œæˆï¼')
